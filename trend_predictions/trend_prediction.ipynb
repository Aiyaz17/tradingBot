{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas-ta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_ta as ta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/22Y/22Y_tatasteel_1D.csv\",index_col=\"date\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding indicators\n",
    "data['RSI']=ta.rsi(data.close, length=15)\n",
    "data['EMA_20']=ta.ema(data.close, length=20)\n",
    "data['EMA_100']=ta.ema(data.close, length=100)\n",
    "data['EMA_150']=ta.ema(data.close, length=150)\n",
    "data['EMA_200']=ta.ema(data.close, length=200)\n",
    "data['EMA_500']=ta.ema(data.close, length=500)\n",
    "\n",
    "\n",
    "data['target'] = data['close']-data.open\n",
    "data['target'] = data['target'].shift(-1)\n",
    "\n",
    "data['trend'] = [1 if data.target[i]>0 else 0 for i in range(len(data))]\n",
    "\n",
    "# Dropping null values after adding indicators and features\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(inplace = True)\n",
    "# data.drop(['volume', 'date'], axis=1, inplace=True) # not required\n",
    "data.drop([ 'date','target'], axis=1, inplace=True) # not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "data_set_scaled = sc.fit_transform(data)\n",
    "print(data_set_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating X,Y sets\n",
    "X = []\n",
    "backcandles = 30\n",
    "for j in range(data_set_scaled[0].size-1): # for each col\n",
    "    X.append([])\n",
    "    for i in range(backcandles, data_set_scaled.shape[0]): # for each data set, store curr col value of last 30 (backcandles) days\n",
    "        X[j].append(data_set_scaled[i-backcandles:i, j])\n",
    "\n",
    "#move axis from 0 to position 2\n",
    "X=np.moveaxis(X, [0], [2])\n",
    "print(X.shape)\n",
    "\n",
    "# creating y and converting x to np array\n",
    "X, yi =np.array(X), np.array(data_set_scaled[backcandles:,-1])\n",
    "# rows from 30th position to end cuz, we can't create training set for first 30 days, min 30 day required\n",
    "# -1 because we are predicting trend which is last in cols\n",
    "\n",
    "y=np.reshape(yi,(len(yi),1)) \n",
    "# converting 1d array to 2d ([1,2,3,4]--> [[1],[2],[3],[4]])\n",
    "#  \n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import History\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Input, Activation, concatenate\n",
    "import numpy as np\n",
    "#tf.random.set_seed(20)\n",
    "np.random.seed(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## THE OG\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(X_train.shape[1], X_train.shape[2]), name='lstm_input'))\n",
    "\n",
    "model.add(LSTM(150, name='first_layer',activation=\"relu\"))\n",
    "model.add(Dense(1, name='dense_layer',activation=\"sigmoid\"))\n",
    "\n",
    "model.compile( loss = 'mean_squared_error', optimizer=optimizers.Adam())\n",
    "model.fit(x=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "X_pred = model.predict(X_train)\n",
    "# input size = X,30,12\n",
    "# where, X = number of predictig examples\n",
    "# 30 = look back days which is 30 in our case\n",
    "# 12 = number of featues\n",
    "\n",
    "# so we will be proving all 12 features of previuos 30 days. and each 30 day will be considered as 1 set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(pred):\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i]>=0.5:\n",
    "            pred[i]=1\n",
    "        else:\n",
    "            pred[i]=0\n",
    "classify(y_pred)\n",
    "classify(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"on training data - \",accuracy_score(X_pred,y_train))\n",
    "print(\"on test data - \",accuracy_score(y_pred,y_test))\n",
    "# increasing number of layers did increased the accurarcy to 0.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('../models/lstm_trend_1.0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
